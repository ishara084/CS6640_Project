{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# EfficientNet (Transfer Learning)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21c8f23ebd8a1e35"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from ptflops import get_model_complexity_info\n",
    "from torchsummary import summary\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Import custom utility module\n",
    "from utils import get_transform, prepare_train_test_data, calculate_evaluation_metrics"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-30T04:53:13.012825400Z",
     "start_time": "2024-11-30T04:52:44.817405400Z"
    }
   },
   "id": "41eca1968df2ebf1"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-30T04:53:13.066401300Z",
     "start_time": "2024-11-30T04:53:13.013833Z"
    }
   },
   "id": "50289ef829534d37"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load and prepare the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d0f2326ad4f29d1"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Transform data\n",
    "image_input_size = (3, 256, 256) # Image input size for the model\n",
    "transform = get_transform(resize_image_size = (256, 256))\n",
    "\n",
    "# Prepare Train/Val/Test Data\n",
    "train_loader, val_loader, test_loader = prepare_train_test_data(transform)\n",
    "\n",
    "# Model keyword\n",
    "model_keyword = \"efficientnet\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-30T04:53:35.615038900Z",
     "start_time": "2024-11-30T04:53:13.064387700Z"
    }
   },
   "id": "e754bf0570346a4d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load pre-trained EfficientNet model and modify it"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ed2bf3c9fa67487"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishar\\.virtualenvs\\ML_env\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ishar\\.virtualenvs\\ML_env\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 128, 128]             864\n",
      "       BatchNorm2d-2         [-1, 32, 128, 128]              64\n",
      "              SiLU-3         [-1, 32, 128, 128]               0\n",
      "            Conv2d-4         [-1, 32, 128, 128]             288\n",
      "       BatchNorm2d-5         [-1, 32, 128, 128]              64\n",
      "              SiLU-6         [-1, 32, 128, 128]               0\n",
      " AdaptiveAvgPool2d-7             [-1, 32, 1, 1]               0\n",
      "            Conv2d-8              [-1, 8, 1, 1]             264\n",
      "              SiLU-9              [-1, 8, 1, 1]               0\n",
      "           Conv2d-10             [-1, 32, 1, 1]             288\n",
      "          Sigmoid-11             [-1, 32, 1, 1]               0\n",
      "SqueezeExcitation-12         [-1, 32, 128, 128]               0\n",
      "           Conv2d-13         [-1, 16, 128, 128]             512\n",
      "      BatchNorm2d-14         [-1, 16, 128, 128]              32\n",
      "           MBConv-15         [-1, 16, 128, 128]               0\n",
      "           Conv2d-16         [-1, 96, 128, 128]           1,536\n",
      "      BatchNorm2d-17         [-1, 96, 128, 128]             192\n",
      "             SiLU-18         [-1, 96, 128, 128]               0\n",
      "           Conv2d-19           [-1, 96, 64, 64]             864\n",
      "      BatchNorm2d-20           [-1, 96, 64, 64]             192\n",
      "             SiLU-21           [-1, 96, 64, 64]               0\n",
      "AdaptiveAvgPool2d-22             [-1, 96, 1, 1]               0\n",
      "           Conv2d-23              [-1, 4, 1, 1]             388\n",
      "             SiLU-24              [-1, 4, 1, 1]               0\n",
      "           Conv2d-25             [-1, 96, 1, 1]             480\n",
      "          Sigmoid-26             [-1, 96, 1, 1]               0\n",
      "SqueezeExcitation-27           [-1, 96, 64, 64]               0\n",
      "           Conv2d-28           [-1, 24, 64, 64]           2,304\n",
      "      BatchNorm2d-29           [-1, 24, 64, 64]              48\n",
      "           MBConv-30           [-1, 24, 64, 64]               0\n",
      "           Conv2d-31          [-1, 144, 64, 64]           3,456\n",
      "      BatchNorm2d-32          [-1, 144, 64, 64]             288\n",
      "             SiLU-33          [-1, 144, 64, 64]               0\n",
      "           Conv2d-34          [-1, 144, 64, 64]           1,296\n",
      "      BatchNorm2d-35          [-1, 144, 64, 64]             288\n",
      "             SiLU-36          [-1, 144, 64, 64]               0\n",
      "AdaptiveAvgPool2d-37            [-1, 144, 1, 1]               0\n",
      "           Conv2d-38              [-1, 6, 1, 1]             870\n",
      "             SiLU-39              [-1, 6, 1, 1]               0\n",
      "           Conv2d-40            [-1, 144, 1, 1]           1,008\n",
      "          Sigmoid-41            [-1, 144, 1, 1]               0\n",
      "SqueezeExcitation-42          [-1, 144, 64, 64]               0\n",
      "           Conv2d-43           [-1, 24, 64, 64]           3,456\n",
      "      BatchNorm2d-44           [-1, 24, 64, 64]              48\n",
      "  StochasticDepth-45           [-1, 24, 64, 64]               0\n",
      "           MBConv-46           [-1, 24, 64, 64]               0\n",
      "           Conv2d-47          [-1, 144, 64, 64]           3,456\n",
      "      BatchNorm2d-48          [-1, 144, 64, 64]             288\n",
      "             SiLU-49          [-1, 144, 64, 64]               0\n",
      "           Conv2d-50          [-1, 144, 32, 32]           3,600\n",
      "      BatchNorm2d-51          [-1, 144, 32, 32]             288\n",
      "             SiLU-52          [-1, 144, 32, 32]               0\n",
      "AdaptiveAvgPool2d-53            [-1, 144, 1, 1]               0\n",
      "           Conv2d-54              [-1, 6, 1, 1]             870\n",
      "             SiLU-55              [-1, 6, 1, 1]               0\n",
      "           Conv2d-56            [-1, 144, 1, 1]           1,008\n",
      "          Sigmoid-57            [-1, 144, 1, 1]               0\n",
      "SqueezeExcitation-58          [-1, 144, 32, 32]               0\n",
      "           Conv2d-59           [-1, 40, 32, 32]           5,760\n",
      "      BatchNorm2d-60           [-1, 40, 32, 32]              80\n",
      "           MBConv-61           [-1, 40, 32, 32]               0\n",
      "           Conv2d-62          [-1, 240, 32, 32]           9,600\n",
      "      BatchNorm2d-63          [-1, 240, 32, 32]             480\n",
      "             SiLU-64          [-1, 240, 32, 32]               0\n",
      "           Conv2d-65          [-1, 240, 32, 32]           6,000\n",
      "      BatchNorm2d-66          [-1, 240, 32, 32]             480\n",
      "             SiLU-67          [-1, 240, 32, 32]               0\n",
      "AdaptiveAvgPool2d-68            [-1, 240, 1, 1]               0\n",
      "           Conv2d-69             [-1, 10, 1, 1]           2,410\n",
      "             SiLU-70             [-1, 10, 1, 1]               0\n",
      "           Conv2d-71            [-1, 240, 1, 1]           2,640\n",
      "          Sigmoid-72            [-1, 240, 1, 1]               0\n",
      "SqueezeExcitation-73          [-1, 240, 32, 32]               0\n",
      "           Conv2d-74           [-1, 40, 32, 32]           9,600\n",
      "      BatchNorm2d-75           [-1, 40, 32, 32]              80\n",
      "  StochasticDepth-76           [-1, 40, 32, 32]               0\n",
      "           MBConv-77           [-1, 40, 32, 32]               0\n",
      "           Conv2d-78          [-1, 240, 32, 32]           9,600\n",
      "      BatchNorm2d-79          [-1, 240, 32, 32]             480\n",
      "             SiLU-80          [-1, 240, 32, 32]               0\n",
      "           Conv2d-81          [-1, 240, 16, 16]           2,160\n",
      "      BatchNorm2d-82          [-1, 240, 16, 16]             480\n",
      "             SiLU-83          [-1, 240, 16, 16]               0\n",
      "AdaptiveAvgPool2d-84            [-1, 240, 1, 1]               0\n",
      "           Conv2d-85             [-1, 10, 1, 1]           2,410\n",
      "             SiLU-86             [-1, 10, 1, 1]               0\n",
      "           Conv2d-87            [-1, 240, 1, 1]           2,640\n",
      "          Sigmoid-88            [-1, 240, 1, 1]               0\n",
      "SqueezeExcitation-89          [-1, 240, 16, 16]               0\n",
      "           Conv2d-90           [-1, 80, 16, 16]          19,200\n",
      "      BatchNorm2d-91           [-1, 80, 16, 16]             160\n",
      "           MBConv-92           [-1, 80, 16, 16]               0\n",
      "           Conv2d-93          [-1, 480, 16, 16]          38,400\n",
      "      BatchNorm2d-94          [-1, 480, 16, 16]             960\n",
      "             SiLU-95          [-1, 480, 16, 16]               0\n",
      "           Conv2d-96          [-1, 480, 16, 16]           4,320\n",
      "      BatchNorm2d-97          [-1, 480, 16, 16]             960\n",
      "             SiLU-98          [-1, 480, 16, 16]               0\n",
      "AdaptiveAvgPool2d-99            [-1, 480, 1, 1]               0\n",
      "          Conv2d-100             [-1, 20, 1, 1]           9,620\n",
      "            SiLU-101             [-1, 20, 1, 1]               0\n",
      "          Conv2d-102            [-1, 480, 1, 1]          10,080\n",
      "         Sigmoid-103            [-1, 480, 1, 1]               0\n",
      "SqueezeExcitation-104          [-1, 480, 16, 16]               0\n",
      "          Conv2d-105           [-1, 80, 16, 16]          38,400\n",
      "     BatchNorm2d-106           [-1, 80, 16, 16]             160\n",
      " StochasticDepth-107           [-1, 80, 16, 16]               0\n",
      "          MBConv-108           [-1, 80, 16, 16]               0\n",
      "          Conv2d-109          [-1, 480, 16, 16]          38,400\n",
      "     BatchNorm2d-110          [-1, 480, 16, 16]             960\n",
      "            SiLU-111          [-1, 480, 16, 16]               0\n",
      "          Conv2d-112          [-1, 480, 16, 16]           4,320\n",
      "     BatchNorm2d-113          [-1, 480, 16, 16]             960\n",
      "            SiLU-114          [-1, 480, 16, 16]               0\n",
      "AdaptiveAvgPool2d-115            [-1, 480, 1, 1]               0\n",
      "          Conv2d-116             [-1, 20, 1, 1]           9,620\n",
      "            SiLU-117             [-1, 20, 1, 1]               0\n",
      "          Conv2d-118            [-1, 480, 1, 1]          10,080\n",
      "         Sigmoid-119            [-1, 480, 1, 1]               0\n",
      "SqueezeExcitation-120          [-1, 480, 16, 16]               0\n",
      "          Conv2d-121           [-1, 80, 16, 16]          38,400\n",
      "     BatchNorm2d-122           [-1, 80, 16, 16]             160\n",
      " StochasticDepth-123           [-1, 80, 16, 16]               0\n",
      "          MBConv-124           [-1, 80, 16, 16]               0\n",
      "          Conv2d-125          [-1, 480, 16, 16]          38,400\n",
      "     BatchNorm2d-126          [-1, 480, 16, 16]             960\n",
      "            SiLU-127          [-1, 480, 16, 16]               0\n",
      "          Conv2d-128          [-1, 480, 16, 16]          12,000\n",
      "     BatchNorm2d-129          [-1, 480, 16, 16]             960\n",
      "            SiLU-130          [-1, 480, 16, 16]               0\n",
      "AdaptiveAvgPool2d-131            [-1, 480, 1, 1]               0\n",
      "          Conv2d-132             [-1, 20, 1, 1]           9,620\n",
      "            SiLU-133             [-1, 20, 1, 1]               0\n",
      "          Conv2d-134            [-1, 480, 1, 1]          10,080\n",
      "         Sigmoid-135            [-1, 480, 1, 1]               0\n",
      "SqueezeExcitation-136          [-1, 480, 16, 16]               0\n",
      "          Conv2d-137          [-1, 112, 16, 16]          53,760\n",
      "     BatchNorm2d-138          [-1, 112, 16, 16]             224\n",
      "          MBConv-139          [-1, 112, 16, 16]               0\n",
      "          Conv2d-140          [-1, 672, 16, 16]          75,264\n",
      "     BatchNorm2d-141          [-1, 672, 16, 16]           1,344\n",
      "            SiLU-142          [-1, 672, 16, 16]               0\n",
      "          Conv2d-143          [-1, 672, 16, 16]          16,800\n",
      "     BatchNorm2d-144          [-1, 672, 16, 16]           1,344\n",
      "            SiLU-145          [-1, 672, 16, 16]               0\n",
      "AdaptiveAvgPool2d-146            [-1, 672, 1, 1]               0\n",
      "          Conv2d-147             [-1, 28, 1, 1]          18,844\n",
      "            SiLU-148             [-1, 28, 1, 1]               0\n",
      "          Conv2d-149            [-1, 672, 1, 1]          19,488\n",
      "         Sigmoid-150            [-1, 672, 1, 1]               0\n",
      "SqueezeExcitation-151          [-1, 672, 16, 16]               0\n",
      "          Conv2d-152          [-1, 112, 16, 16]          75,264\n",
      "     BatchNorm2d-153          [-1, 112, 16, 16]             224\n",
      " StochasticDepth-154          [-1, 112, 16, 16]               0\n",
      "          MBConv-155          [-1, 112, 16, 16]               0\n",
      "          Conv2d-156          [-1, 672, 16, 16]          75,264\n",
      "     BatchNorm2d-157          [-1, 672, 16, 16]           1,344\n",
      "            SiLU-158          [-1, 672, 16, 16]               0\n",
      "          Conv2d-159          [-1, 672, 16, 16]          16,800\n",
      "     BatchNorm2d-160          [-1, 672, 16, 16]           1,344\n",
      "            SiLU-161          [-1, 672, 16, 16]               0\n",
      "AdaptiveAvgPool2d-162            [-1, 672, 1, 1]               0\n",
      "          Conv2d-163             [-1, 28, 1, 1]          18,844\n",
      "            SiLU-164             [-1, 28, 1, 1]               0\n",
      "          Conv2d-165            [-1, 672, 1, 1]          19,488\n",
      "         Sigmoid-166            [-1, 672, 1, 1]               0\n",
      "SqueezeExcitation-167          [-1, 672, 16, 16]               0\n",
      "          Conv2d-168          [-1, 112, 16, 16]          75,264\n",
      "     BatchNorm2d-169          [-1, 112, 16, 16]             224\n",
      " StochasticDepth-170          [-1, 112, 16, 16]               0\n",
      "          MBConv-171          [-1, 112, 16, 16]               0\n",
      "          Conv2d-172          [-1, 672, 16, 16]          75,264\n",
      "     BatchNorm2d-173          [-1, 672, 16, 16]           1,344\n",
      "            SiLU-174          [-1, 672, 16, 16]               0\n",
      "          Conv2d-175            [-1, 672, 8, 8]          16,800\n",
      "     BatchNorm2d-176            [-1, 672, 8, 8]           1,344\n",
      "            SiLU-177            [-1, 672, 8, 8]               0\n",
      "AdaptiveAvgPool2d-178            [-1, 672, 1, 1]               0\n",
      "          Conv2d-179             [-1, 28, 1, 1]          18,844\n",
      "            SiLU-180             [-1, 28, 1, 1]               0\n",
      "          Conv2d-181            [-1, 672, 1, 1]          19,488\n",
      "         Sigmoid-182            [-1, 672, 1, 1]               0\n",
      "SqueezeExcitation-183            [-1, 672, 8, 8]               0\n",
      "          Conv2d-184            [-1, 192, 8, 8]         129,024\n",
      "     BatchNorm2d-185            [-1, 192, 8, 8]             384\n",
      "          MBConv-186            [-1, 192, 8, 8]               0\n",
      "          Conv2d-187           [-1, 1152, 8, 8]         221,184\n",
      "     BatchNorm2d-188           [-1, 1152, 8, 8]           2,304\n",
      "            SiLU-189           [-1, 1152, 8, 8]               0\n",
      "          Conv2d-190           [-1, 1152, 8, 8]          28,800\n",
      "     BatchNorm2d-191           [-1, 1152, 8, 8]           2,304\n",
      "            SiLU-192           [-1, 1152, 8, 8]               0\n",
      "AdaptiveAvgPool2d-193           [-1, 1152, 1, 1]               0\n",
      "          Conv2d-194             [-1, 48, 1, 1]          55,344\n",
      "            SiLU-195             [-1, 48, 1, 1]               0\n",
      "          Conv2d-196           [-1, 1152, 1, 1]          56,448\n",
      "         Sigmoid-197           [-1, 1152, 1, 1]               0\n",
      "SqueezeExcitation-198           [-1, 1152, 8, 8]               0\n",
      "          Conv2d-199            [-1, 192, 8, 8]         221,184\n",
      "     BatchNorm2d-200            [-1, 192, 8, 8]             384\n",
      " StochasticDepth-201            [-1, 192, 8, 8]               0\n",
      "          MBConv-202            [-1, 192, 8, 8]               0\n",
      "          Conv2d-203           [-1, 1152, 8, 8]         221,184\n",
      "     BatchNorm2d-204           [-1, 1152, 8, 8]           2,304\n",
      "            SiLU-205           [-1, 1152, 8, 8]               0\n",
      "          Conv2d-206           [-1, 1152, 8, 8]          28,800\n",
      "     BatchNorm2d-207           [-1, 1152, 8, 8]           2,304\n",
      "            SiLU-208           [-1, 1152, 8, 8]               0\n",
      "AdaptiveAvgPool2d-209           [-1, 1152, 1, 1]               0\n",
      "          Conv2d-210             [-1, 48, 1, 1]          55,344\n",
      "            SiLU-211             [-1, 48, 1, 1]               0\n",
      "          Conv2d-212           [-1, 1152, 1, 1]          56,448\n",
      "         Sigmoid-213           [-1, 1152, 1, 1]               0\n",
      "SqueezeExcitation-214           [-1, 1152, 8, 8]               0\n",
      "          Conv2d-215            [-1, 192, 8, 8]         221,184\n",
      "     BatchNorm2d-216            [-1, 192, 8, 8]             384\n",
      " StochasticDepth-217            [-1, 192, 8, 8]               0\n",
      "          MBConv-218            [-1, 192, 8, 8]               0\n",
      "          Conv2d-219           [-1, 1152, 8, 8]         221,184\n",
      "     BatchNorm2d-220           [-1, 1152, 8, 8]           2,304\n",
      "            SiLU-221           [-1, 1152, 8, 8]               0\n",
      "          Conv2d-222           [-1, 1152, 8, 8]          28,800\n",
      "     BatchNorm2d-223           [-1, 1152, 8, 8]           2,304\n",
      "            SiLU-224           [-1, 1152, 8, 8]               0\n",
      "AdaptiveAvgPool2d-225           [-1, 1152, 1, 1]               0\n",
      "          Conv2d-226             [-1, 48, 1, 1]          55,344\n",
      "            SiLU-227             [-1, 48, 1, 1]               0\n",
      "          Conv2d-228           [-1, 1152, 1, 1]          56,448\n",
      "         Sigmoid-229           [-1, 1152, 1, 1]               0\n",
      "SqueezeExcitation-230           [-1, 1152, 8, 8]               0\n",
      "          Conv2d-231            [-1, 192, 8, 8]         221,184\n",
      "     BatchNorm2d-232            [-1, 192, 8, 8]             384\n",
      " StochasticDepth-233            [-1, 192, 8, 8]               0\n",
      "          MBConv-234            [-1, 192, 8, 8]               0\n",
      "          Conv2d-235           [-1, 1152, 8, 8]         221,184\n",
      "     BatchNorm2d-236           [-1, 1152, 8, 8]           2,304\n",
      "            SiLU-237           [-1, 1152, 8, 8]               0\n",
      "          Conv2d-238           [-1, 1152, 8, 8]          10,368\n",
      "     BatchNorm2d-239           [-1, 1152, 8, 8]           2,304\n",
      "            SiLU-240           [-1, 1152, 8, 8]               0\n",
      "AdaptiveAvgPool2d-241           [-1, 1152, 1, 1]               0\n",
      "          Conv2d-242             [-1, 48, 1, 1]          55,344\n",
      "            SiLU-243             [-1, 48, 1, 1]               0\n",
      "          Conv2d-244           [-1, 1152, 1, 1]          56,448\n",
      "         Sigmoid-245           [-1, 1152, 1, 1]               0\n",
      "SqueezeExcitation-246           [-1, 1152, 8, 8]               0\n",
      "          Conv2d-247            [-1, 320, 8, 8]         368,640\n",
      "     BatchNorm2d-248            [-1, 320, 8, 8]             640\n",
      "          MBConv-249            [-1, 320, 8, 8]               0\n",
      "          Conv2d-250           [-1, 1280, 8, 8]         409,600\n",
      "     BatchNorm2d-251           [-1, 1280, 8, 8]           2,560\n",
      "            SiLU-252           [-1, 1280, 8, 8]               0\n",
      "AdaptiveAvgPool2d-253           [-1, 1280, 1, 1]               0\n",
      "          Linear-254                    [-1, 2]           2,562\n",
      "================================================================\n",
      "Total params: 4,010,110\n",
      "Trainable params: 4,010,110\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 226.72\n",
      "Params size (MB): 15.30\n",
      "Estimated Total Size (MB): 242.77\n",
      "----------------------------------------------------------------\n",
      "Total number of layers: 335\n"
     ]
    }
   ],
   "source": [
    "# Load EfficientNet model\n",
    "model = models.efficientnet_b0(pretrained=True)\n",
    "\n",
    "# Modify the classifier for binary classification\n",
    "num_features = model.classifier[1].in_features\n",
    "model.classifier = nn.Linear(num_features, 2)  # Binary classification: Internal waves (1) or No waves (0)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.1) # Implement a learning rate scheduler to adjust the learning rate during training\n",
    "\n",
    "# Print the summary for EfficientNet\n",
    "summary(model, input_size=image_input_size, device=str(device))\n",
    "print(f\"Total number of layers: {sum(1 for _ in model.modules())}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-30T04:53:36.656850100Z",
     "start_time": "2024-11-30T04:53:35.616046Z"
    }
   },
   "id": "a6b7d18da9b9231b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "452a3507cab1d33f"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Train Loss: 0.3566, Val Loss: 0.3588, Val Accuracy: 84.73%, GFLOPs: 0.53\n",
      "Epoch [2/50], Train Loss: 0.2351, Val Loss: 0.1908, Val Accuracy: 91.92%, GFLOPs: 0.53\n",
      "Epoch [3/50], Train Loss: 0.1480, Val Loss: 0.2703, Val Accuracy: 92.22%, GFLOPs: 0.53\n",
      "Epoch [4/50], Train Loss: 0.1469, Val Loss: 0.1928, Val Accuracy: 93.83%, GFLOPs: 0.53\n",
      "Epoch [5/50], Train Loss: 0.1134, Val Loss: 0.1743, Val Accuracy: 94.13%, GFLOPs: 0.53\n",
      "Epoch [6/50], Train Loss: 0.0787, Val Loss: 0.1978, Val Accuracy: 92.95%, GFLOPs: 0.53\n",
      "Epoch [7/50], Train Loss: 0.0805, Val Loss: 0.1622, Val Accuracy: 94.86%, GFLOPs: 0.53\n",
      "Epoch [8/50], Train Loss: 0.0433, Val Loss: 0.1363, Val Accuracy: 95.01%, GFLOPs: 0.53\n",
      "Epoch [9/50], Train Loss: 0.0287, Val Loss: 0.1498, Val Accuracy: 95.45%, GFLOPs: 0.53\n",
      "Epoch [10/50], Train Loss: 0.0418, Val Loss: 0.1151, Val Accuracy: 96.04%, GFLOPs: 0.53\n",
      "Epoch [11/50], Train Loss: 0.0432, Val Loss: 0.2488, Val Accuracy: 91.48%, GFLOPs: 0.53\n",
      "Epoch [12/50], Train Loss: 0.0340, Val Loss: 0.1427, Val Accuracy: 94.27%, GFLOPs: 0.53\n",
      "Epoch [13/50], Train Loss: 0.0634, Val Loss: 0.1660, Val Accuracy: 94.13%, GFLOPs: 0.53\n",
      "Epoch [14/50], Train Loss: 0.0465, Val Loss: 0.1203, Val Accuracy: 95.15%, GFLOPs: 0.53\n",
      "Epoch [15/50], Train Loss: 0.0341, Val Loss: 0.1376, Val Accuracy: 94.42%, GFLOPs: 0.53\n",
      "Epoch [16/50], Train Loss: 0.0343, Val Loss: 0.1611, Val Accuracy: 94.71%, GFLOPs: 0.53\n",
      "Epoch [17/50], Train Loss: 0.0168, Val Loss: 0.1141, Val Accuracy: 96.33%, GFLOPs: 0.53\n",
      "Epoch [18/50], Train Loss: 0.0078, Val Loss: 0.1125, Val Accuracy: 95.89%, GFLOPs: 0.53\n",
      "Epoch [19/50], Train Loss: 0.0064, Val Loss: 0.1152, Val Accuracy: 95.74%, GFLOPs: 0.53\n",
      "Epoch [20/50], Train Loss: 0.0050, Val Loss: 0.1112, Val Accuracy: 96.18%, GFLOPs: 0.53\n",
      "Epoch [21/50], Train Loss: 0.0043, Val Loss: 0.1063, Val Accuracy: 96.33%, GFLOPs: 0.53\n",
      "Epoch [22/50], Train Loss: 0.0033, Val Loss: 0.1055, Val Accuracy: 96.62%, GFLOPs: 0.53\n",
      "Epoch [23/50], Train Loss: 0.0040, Val Loss: 0.1054, Val Accuracy: 96.62%, GFLOPs: 0.53\n",
      "Epoch [24/50], Train Loss: 0.0034, Val Loss: 0.0987, Val Accuracy: 96.77%, GFLOPs: 0.53\n",
      "Epoch [25/50], Train Loss: 0.0026, Val Loss: 0.1095, Val Accuracy: 96.33%, GFLOPs: 0.53\n",
      "Epoch [26/50], Train Loss: 0.0029, Val Loss: 0.1102, Val Accuracy: 97.06%, GFLOPs: 0.53\n",
      "Epoch [27/50], Train Loss: 0.0031, Val Loss: 0.1074, Val Accuracy: 97.06%, GFLOPs: 0.53\n",
      "Epoch [28/50], Train Loss: 0.0012, Val Loss: 0.1104, Val Accuracy: 97.06%, GFLOPs: 0.53\n",
      "Epoch [29/50], Train Loss: 0.0018, Val Loss: 0.1177, Val Accuracy: 96.62%, GFLOPs: 0.53\n",
      "Epoch [30/50], Train Loss: 0.0012, Val Loss: 0.1283, Val Accuracy: 96.48%, GFLOPs: 0.53\n",
      "Epoch [31/50], Train Loss: 0.0028, Val Loss: 0.1212, Val Accuracy: 96.62%, GFLOPs: 0.53\n",
      "Epoch [32/50], Train Loss: 0.0022, Val Loss: 0.1161, Val Accuracy: 96.77%, GFLOPs: 0.53\n",
      "Epoch [33/50], Train Loss: 0.0014, Val Loss: 0.1202, Val Accuracy: 96.77%, GFLOPs: 0.53\n",
      "Epoch [34/50], Train Loss: 0.0011, Val Loss: 0.1138, Val Accuracy: 96.92%, GFLOPs: 0.53\n",
      "Epoch [35/50], Train Loss: 0.0013, Val Loss: 0.1156, Val Accuracy: 97.06%, GFLOPs: 0.53\n",
      "Epoch [36/50], Train Loss: 0.0029, Val Loss: 0.1217, Val Accuracy: 96.77%, GFLOPs: 0.53\n",
      "Epoch [37/50], Train Loss: 0.0006, Val Loss: 0.1234, Val Accuracy: 96.77%, GFLOPs: 0.53\n",
      "Epoch [38/50], Train Loss: 0.0016, Val Loss: 0.1203, Val Accuracy: 96.77%, GFLOPs: 0.53\n",
      "Epoch [39/50], Train Loss: 0.0019, Val Loss: 0.1179, Val Accuracy: 96.62%, GFLOPs: 0.53\n",
      "Epoch [40/50], Train Loss: 0.0018, Val Loss: 0.1184, Val Accuracy: 96.77%, GFLOPs: 0.53\n",
      "Epoch [41/50], Train Loss: 0.0015, Val Loss: 0.1233, Val Accuracy: 96.62%, GFLOPs: 0.53\n",
      "Epoch [42/50], Train Loss: 0.0018, Val Loss: 0.1234, Val Accuracy: 96.77%, GFLOPs: 0.53\n",
      "Epoch [43/50], Train Loss: 0.0021, Val Loss: 0.1159, Val Accuracy: 96.92%, GFLOPs: 0.53\n",
      "Epoch [44/50], Train Loss: 0.0023, Val Loss: 0.1136, Val Accuracy: 96.77%, GFLOPs: 0.53\n",
      "Epoch [45/50], Train Loss: 0.0004, Val Loss: 0.1172, Val Accuracy: 96.92%, GFLOPs: 0.53\n",
      "Epoch [46/50], Train Loss: 0.0028, Val Loss: 0.1187, Val Accuracy: 97.06%, GFLOPs: 0.53\n",
      "Epoch [47/50], Train Loss: 0.0041, Val Loss: 0.1218, Val Accuracy: 96.62%, GFLOPs: 0.53\n",
      "Epoch [48/50], Train Loss: 0.0011, Val Loss: 0.1118, Val Accuracy: 96.77%, GFLOPs: 0.53\n",
      "Epoch [49/50], Train Loss: 0.0004, Val Loss: 0.1160, Val Accuracy: 96.92%, GFLOPs: 0.53\n",
      "Epoch [50/50], Train Loss: 0.0013, Val Loss: 0.1165, Val Accuracy: 96.92%, GFLOPs: 0.53\n",
      "\n",
      "Total Training Time: 1646.64 seconds\n"
     ]
    }
   ],
   "source": [
    "# Initialize a DataFrame to log training/validation metrics\n",
    "log_df = []\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "best_val_loss = float('inf')  # Initialize best validation loss for saving the model\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_accuracy = val_correct / val_total * 100\n",
    "    \n",
    "    # Adjust learning rate\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Calculate FLOPs after each epoch\n",
    "    with torch.no_grad():\n",
    "        flops, _ = get_model_complexity_info(model, image_input_size, as_strings=False, print_per_layer_stat=False)\n",
    "\n",
    "    # Log metrics into the DataFrame\n",
    "    new_row = {\n",
    "        \"Epoch\": epoch + 1,\n",
    "        \"Train_Loss\": train_loss / len(train_loader),\n",
    "        \"Validation_Loss\": val_loss / len(val_loader),\n",
    "        \"Validation_Accuracy\": val_accuracy,\n",
    "        \"FLOPs\": flops\n",
    "    }\n",
    "    log_df.append(new_row)\n",
    "\n",
    "    # Print metrics for this epoch\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss / len(train_loader):.4f}, \"\n",
    "          f\"Val Loss: {val_loss / len(val_loader):.4f}, Val Accuracy: {val_accuracy:.2f}%, \"\n",
    "          f\"GFLOPs: {(flops / 1e9 ):.2f}\")\n",
    "\n",
    "    # Save the best model based on validation loss\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), f\"model_outputs_data/best_{model_keyword}_model.pth\")\n",
    "\n",
    "# Calculate the total training time in seconds\n",
    "print(f\"\\nTotal Training Time: {(time.time() - start_time):.2f} seconds\")\n",
    "\n",
    "# Save the DataFrame to a CSV file for later use\n",
    "log_df = pd.DataFrame(log_df)\n",
    "log_df.to_csv(f\"model_outputs_data/model_evaluation_logs/training_logs_{model_keyword}.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-30T05:21:03.322196900Z",
     "start_time": "2024-11-30T04:53:36.656850100Z"
    }
   },
   "id": "a765573938f8131d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prediction and Model evaluation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3ab8b35cd783866"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 96.37%\n",
      "Precision: 0.98\n",
      "Recall: 0.95\n",
      "F1-Score: 0.96\n",
      "\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "No Internal Waves       0.95      0.98      0.96       719\n",
      "   Internal Waves       0.98      0.95      0.96       740\n",
      "\n",
      "         accuracy                           0.96      1459\n",
      "        macro avg       0.96      0.96      0.96      1459\n",
      "     weighted avg       0.96      0.96      0.96      1459\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[703  16]\n",
      " [ 37 703]]\n",
      "\n",
      " Predictions saved to model_outputs_data/model_prediction_logs/efficientnet_labels_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "# Load the best model for testing\n",
    "# model.load_state_dict(torch.load(f\"model_outputs_data/best_{model_keyword}_model.pth\"))\n",
    "\n",
    "# Test the model\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "all_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_probs.extend(probabilities[:, 1].cpu().numpy())\n",
    "\n",
    "# Print evaluation metrics\n",
    "calculate_evaluation_metrics(all_labels, all_preds, all_probs, model_keyword)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-30T05:21:16.709102100Z",
     "start_time": "2024-11-30T05:21:03.317936Z"
    }
   },
   "id": "1cbd6ad53101af08"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
