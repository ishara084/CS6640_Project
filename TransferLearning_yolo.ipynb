{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import shutil\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T01:30:23.921937200Z",
     "start_time": "2024-11-19T01:30:23.853844300Z"
    }
   },
   "id": "cf415cbf764bb7bc"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()  # Clears CUDA memory cache\n",
    "# torch.cuda.reset_peak_memory_stats()\n",
    "# torch.cuda.reset_accumulated_memory_stats()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T01:30:23.938932600Z",
     "start_time": "2024-11-19T01:30:23.858489900Z"
    }
   },
   "id": "d4de8fb762f98a85"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare data for YOLO model input"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c65d2292eddf4e1"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data organization complete.\n"
     ]
    }
   ],
   "source": [
    "# Base directories\n",
    "data_directory = 'data'\n",
    "output_directory = os.path.join('model_outputs_data', 'yolo_output')\n",
    "\n",
    "# Paths to data\n",
    "train_csv_path = os.path.join(data_directory, 'train.csv')\n",
    "test_csv_path = os.path.join(data_directory, 'test.csv')\n",
    "images_train_path = os.path.join(data_directory, 'images_train')\n",
    "images_test_path = os.path.join(data_directory, 'images_test')\n",
    "\n",
    "# Create necessary directories\n",
    "def create_directories(path_list):\n",
    "    for path in path_list:\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "# Setup directories for training and validation\n",
    "train_dir = os.path.join(output_directory, 'train')\n",
    "val_dir = os.path.join(output_directory, 'val')\n",
    "train_0_dir = os.path.join(train_dir, '0')\n",
    "train_1_dir = os.path.join(train_dir, '1')\n",
    "val_0_dir = os.path.join(val_dir, '0')\n",
    "val_1_dir = os.path.join(val_dir, '1')\n",
    "\n",
    "# Create all needed folders\n",
    "create_directories([train_dir, val_dir, train_0_dir, train_1_dir, val_0_dir, val_1_dir])\n",
    "\n",
    "# Method to copy images based on a dataframe, source directory, and target base directory\n",
    "def copy_images(df, src_dir, target_base_dir):\n",
    "    for idx, row in df.iterrows():\n",
    "        file_name = f\"{row['id']}.png\"\n",
    "        src_file_path = os.path.join(src_dir, file_name)\n",
    "        if row['ground_truth'] == 1:\n",
    "            dst_file_path = os.path.join(target_base_dir, '1', file_name)\n",
    "        else:\n",
    "            dst_file_path = os.path.join(target_base_dir, '0', file_name)\n",
    "        shutil.copy(src_file_path, dst_file_path)\n",
    "\n",
    "# Load the data\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "\n",
    "# Split train_df further to create a validation set or use test_df as validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Copy images according to the csv files\n",
    "copy_images(train_df, images_train_path, train_dir)\n",
    "copy_images(val_df, images_train_path, val_dir)  # If using part of train data as val\n",
    "# copy_images(test_df, images_test_path, val_dir)  # Uncomment if test_df should be used as validation\n",
    "\n",
    "print(\"Data organization complete.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T01:30:33.350828300Z",
     "start_time": "2024-11-19T01:30:23.876410900Z"
    }
   },
   "id": "e42e223d16f61de3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Select device\n",
    "I'm using my local GPU with Torch+CUDA for this because it is way faster than using CPU"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "57d444cd7c491a9a"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Select the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T01:30:33.350828300Z",
     "start_time": "2024-11-19T01:30:33.344296Z"
    }
   },
   "id": "6bd24ffe0d99331a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load and Train the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ad4390b97aac4b9"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.33 available  Update with 'pip install -U ultralytics'\n",
      "\u001B[34m\u001B[1mengine\\trainer: \u001B[0mtask=classify, mode=train, model=pre_trained_models/yolov8x-cls.pt, data=data\\yolo_output, epochs=10, time=None, patience=100, batch=16, imgsz=224, save=True, save_period=-1, cache=False, device=cuda, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=42, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\train2\n",
      "\u001B[34m\u001B[1mtrain:\u001B[0m C:\\Projects\\CS6640 - Artificial Neural Networks\\Project\\CS6640_Project\\data\\yolo_output\\train... found 2720 images in 2 classes  \n",
      "\u001B[34m\u001B[1mval:\u001B[0m C:\\Projects\\CS6640 - Artificial Neural Networks\\Project\\CS6640_Project\\data\\yolo_output\\val... found 681 images in 2 classes  \n",
      "\u001B[34m\u001B[1mtest:\u001B[0m None...\n",
      "Overriding model.yaml nc=1000 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
      "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
      "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
      "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
      "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
      "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 6\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# model = YOLO(os.path.join(output_directory, 'pre_trained_models/yolov8x-cls.pt'))  # Yolo8\u001B[39;00m\n\u001B[0;32m      4\u001B[0m model\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m----> 6\u001B[0m train_results \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_directory\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m42\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.virtualenvs\\ML_env\\Lib\\site-packages\\ultralytics\\engine\\model.py:809\u001B[0m, in \u001B[0;36mModel.train\u001B[1;34m(self, trainer, **kwargs)\u001B[0m\n\u001B[0;32m    807\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer \u001B[38;5;241m=\u001B[39m (trainer \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_smart_load(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrainer\u001B[39m\u001B[38;5;124m\"\u001B[39m))(overrides\u001B[38;5;241m=\u001B[39margs, _callbacks\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallbacks)\n\u001B[0;32m    808\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m args\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresume\u001B[39m\u001B[38;5;124m\"\u001B[39m):  \u001B[38;5;66;03m# manually set model only if not resuming\u001B[39;00m\n\u001B[1;32m--> 809\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mweights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mckpt\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcfg\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43myaml\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    810\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mmodel\n\u001B[0;32m    812\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mhub_session \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msession  \u001B[38;5;66;03m# attach optional HUB session\u001B[39;00m\n",
      "File \u001B[1;32m~\\.virtualenvs\\ML_env\\Lib\\site-packages\\ultralytics\\models\\yolo\\classify\\train.py:46\u001B[0m, in \u001B[0;36mClassificationTrainer.get_model\u001B[1;34m(self, cfg, weights, verbose)\u001B[0m\n\u001B[0;32m     44\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_model\u001B[39m(\u001B[38;5;28mself\u001B[39m, cfg\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, weights\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m     45\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Returns a modified PyTorch model configured for training YOLO.\"\"\"\u001B[39;00m\n\u001B[1;32m---> 46\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[43mClassificationModel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcfg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mnc\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mand\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mRANK\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     47\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m weights:\n\u001B[0;32m     48\u001B[0m         model\u001B[38;5;241m.\u001B[39mload(weights)\n",
      "File \u001B[1;32m~\\.virtualenvs\\ML_env\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:436\u001B[0m, in \u001B[0;36mClassificationModel.__init__\u001B[1;34m(self, cfg, ch, nc, verbose)\u001B[0m\n\u001B[0;32m    434\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Init ClassificationModel with YAML, channels, number of classes, verbose flag.\"\"\"\u001B[39;00m\n\u001B[0;32m    435\u001B[0m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m()\n\u001B[1;32m--> 436\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_from_yaml\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcfg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.virtualenvs\\ML_env\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:449\u001B[0m, in \u001B[0;36mClassificationModel._from_yaml\u001B[1;34m(self, cfg, ch, nc, verbose)\u001B[0m\n\u001B[0;32m    447\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m nc \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39myaml\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnc\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    448\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnc not specified. Must specify nc in model.yaml or function arguments.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 449\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msave \u001B[38;5;241m=\u001B[39m \u001B[43mparse_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdeepcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43myaml\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# model, savelist\u001B[39;00m\n\u001B[0;32m    450\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor([\u001B[38;5;241m1\u001B[39m])  \u001B[38;5;66;03m# no stride constraints\u001B[39;00m\n\u001B[0;32m    451\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnames \u001B[38;5;241m=\u001B[39m {i: \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39myaml[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnc\u001B[39m\u001B[38;5;124m\"\u001B[39m])}  \u001B[38;5;66;03m# default names dict\u001B[39;00m\n",
      "File \u001B[1;32m~\\.virtualenvs\\ML_env\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:987\u001B[0m, in \u001B[0;36mparse_model\u001B[1;34m(d, ch, verbose)\u001B[0m\n\u001B[0;32m    984\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    985\u001B[0m     c2 \u001B[38;5;241m=\u001B[39m ch[f]\n\u001B[1;32m--> 987\u001B[0m m_ \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mSequential(\u001B[38;5;241m*\u001B[39m(m(\u001B[38;5;241m*\u001B[39margs) \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n))) \u001B[38;5;28;01mif\u001B[39;00m n \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[43mm\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# module\u001B[39;00m\n\u001B[0;32m    988\u001B[0m t \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(m)[\u001B[38;5;241m8\u001B[39m:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m]\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__.\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)  \u001B[38;5;66;03m# module type\u001B[39;00m\n\u001B[0;32m    989\u001B[0m m\u001B[38;5;241m.\u001B[39mnp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msum\u001B[39m(x\u001B[38;5;241m.\u001B[39mnumel() \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m m_\u001B[38;5;241m.\u001B[39mparameters())  \u001B[38;5;66;03m# number params\u001B[39;00m\n",
      "File \u001B[1;32m~\\.virtualenvs\\ML_env\\Lib\\site-packages\\ultralytics\\nn\\modules\\block.py:230\u001B[0m, in \u001B[0;36mC2f.__init__\u001B[1;34m(self, c1, c2, n, shortcut, g, e)\u001B[0m\n\u001B[0;32m    228\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcv1 \u001B[38;5;241m=\u001B[39m Conv(c1, \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mc, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    229\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcv2 \u001B[38;5;241m=\u001B[39m Conv((\u001B[38;5;241m2\u001B[39m \u001B[38;5;241m+\u001B[39m n) \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mc, c2, \u001B[38;5;241m1\u001B[39m)  \u001B[38;5;66;03m# optional act=FReLU(c2)\u001B[39;00m\n\u001B[1;32m--> 230\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mm \u001B[38;5;241m=\u001B[39m \u001B[43mnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mModuleList\u001B[49m\u001B[43m(\u001B[49m\u001B[43mBottleneck\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshortcut\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43me\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1.0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m_\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mrange\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mn\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.virtualenvs\\ML_env\\Lib\\site-packages\\torch\\nn\\modules\\container.py:310\u001B[0m, in \u001B[0;36mModuleList.__init__\u001B[1;34m(self, modules)\u001B[0m\n\u001B[0;32m    308\u001B[0m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m()\n\u001B[0;32m    309\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m modules \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 310\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mmodules\u001B[49m\n",
      "File \u001B[1;32m~\\.virtualenvs\\ML_env\\Lib\\site-packages\\torch\\nn\\modules\\container.py:359\u001B[0m, in \u001B[0;36mModuleList.__iadd__\u001B[1;34m(self, modules)\u001B[0m\n\u001B[0;32m    358\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__iadd__\u001B[39m(\u001B[38;5;28mself\u001B[39m, modules: Iterable[Module]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Self:\n\u001B[1;32m--> 359\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mextend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodules\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.virtualenvs\\ML_env\\Lib\\site-packages\\torch\\nn\\modules\\container.py:442\u001B[0m, in \u001B[0;36mModuleList.extend\u001B[1;34m(self, modules)\u001B[0m\n\u001B[0;32m    437\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[0;32m    438\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModuleList.extend should be called with an \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    439\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miterable, but got \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mtype\u001B[39m(modules)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\n\u001B[0;32m    440\u001B[0m     )\n\u001B[0;32m    441\u001B[0m offset \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m--> 442\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodule\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mmodules\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[0;32m    443\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_module\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moffset\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodule\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    444\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32m~\\.virtualenvs\\ML_env\\Lib\\site-packages\\ultralytics\\nn\\modules\\block.py:230\u001B[0m, in \u001B[0;36m<genexpr>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    228\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcv1 \u001B[38;5;241m=\u001B[39m Conv(c1, \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mc, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    229\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcv2 \u001B[38;5;241m=\u001B[39m Conv((\u001B[38;5;241m2\u001B[39m \u001B[38;5;241m+\u001B[39m n) \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mc, c2, \u001B[38;5;241m1\u001B[39m)  \u001B[38;5;66;03m# optional act=FReLU(c2)\u001B[39;00m\n\u001B[1;32m--> 230\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mm \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mModuleList(\u001B[43mBottleneck\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshortcut\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43me\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1.0\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n))\n",
      "File \u001B[1;32m~\\.virtualenvs\\ML_env\\Lib\\site-packages\\ultralytics\\nn\\modules\\block.py:338\u001B[0m, in \u001B[0;36mBottleneck.__init__\u001B[1;34m(self, c1, c2, shortcut, g, k, e)\u001B[0m\n\u001B[0;32m    336\u001B[0m c_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(c2 \u001B[38;5;241m*\u001B[39m e)  \u001B[38;5;66;03m# hidden channels\u001B[39;00m\n\u001B[0;32m    337\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcv1 \u001B[38;5;241m=\u001B[39m Conv(c1, c_, k[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m--> 338\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcv2 \u001B[38;5;241m=\u001B[39m \u001B[43mConv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mc_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mc2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mg\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    339\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madd \u001B[38;5;241m=\u001B[39m shortcut \u001B[38;5;129;01mand\u001B[39;00m c1 \u001B[38;5;241m==\u001B[39m c2\n",
      "File \u001B[1;32m~\\.virtualenvs\\ML_env\\Lib\\site-packages\\ultralytics\\nn\\modules\\conv.py:44\u001B[0m, in \u001B[0;36mConv.__init__\u001B[1;34m(self, c1, c2, k, s, p, g, d, act)\u001B[0m\n\u001B[0;32m     42\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Initialize Conv layer with given arguments including activation.\"\"\"\u001B[39;00m\n\u001B[0;32m     43\u001B[0m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m()\n\u001B[1;32m---> 44\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv \u001B[38;5;241m=\u001B[39m \u001B[43mnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mConv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[43mc1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mc2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mautopad\u001B[49m\u001B[43m(\u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43md\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdilation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43md\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     45\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbn \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mBatchNorm2d(c2)\n\u001B[0;32m     46\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mact \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefault_act \u001B[38;5;28;01mif\u001B[39;00m act \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m act \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(act, nn\u001B[38;5;241m.\u001B[39mModule) \u001B[38;5;28;01melse\u001B[39;00m nn\u001B[38;5;241m.\u001B[39mIdentity()\n",
      "File \u001B[1;32m~\\.virtualenvs\\ML_env\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:521\u001B[0m, in \u001B[0;36mConv2d.__init__\u001B[1;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode, device, dtype)\u001B[0m\n\u001B[0;32m    519\u001B[0m padding_ \u001B[38;5;241m=\u001B[39m padding \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(padding, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m _pair(padding)\n\u001B[0;32m    520\u001B[0m dilation_ \u001B[38;5;241m=\u001B[39m _pair(dilation)\n\u001B[1;32m--> 521\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m    522\u001B[0m \u001B[43m    \u001B[49m\u001B[43min_channels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    523\u001B[0m \u001B[43m    \u001B[49m\u001B[43mout_channels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    524\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkernel_size_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    525\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstride_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    526\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpadding_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    527\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdilation_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    528\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    529\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_pair\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    530\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    531\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    532\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpadding_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    533\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfactory_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    534\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.virtualenvs\\ML_env\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:176\u001B[0m, in \u001B[0;36m_ConvNd.__init__\u001B[1;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, bias, padding_mode, device, dtype)\u001B[0m\n\u001B[0;32m    173\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    174\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mregister_parameter(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbias\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m--> 176\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreset_parameters\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.virtualenvs\\ML_env\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:182\u001B[0m, in \u001B[0;36m_ConvNd.reset_parameters\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    178\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mreset_parameters\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    179\u001B[0m     \u001B[38;5;66;03m# Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\u001B[39;00m\n\u001B[0;32m    180\u001B[0m     \u001B[38;5;66;03m# uniform(-1/sqrt(k), 1/sqrt(k)), where k = weight.size(1) * prod(*kernel_size)\u001B[39;00m\n\u001B[0;32m    181\u001B[0m     \u001B[38;5;66;03m# For more details see: https://github.com/pytorch/pytorch/issues/15314#issuecomment-477448573\u001B[39;00m\n\u001B[1;32m--> 182\u001B[0m     \u001B[43minit\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkaiming_uniform_\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ma\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msqrt\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    183\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    184\u001B[0m         fan_in, _ \u001B[38;5;241m=\u001B[39m init\u001B[38;5;241m.\u001B[39m_calculate_fan_in_and_fan_out(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight)\n",
      "File \u001B[1;32m~\\.virtualenvs\\ML_env\\Lib\\site-packages\\torch\\nn\\init.py:518\u001B[0m, in \u001B[0;36mkaiming_uniform_\u001B[1;34m(tensor, a, mode, nonlinearity, generator)\u001B[0m\n\u001B[0;32m    516\u001B[0m bound \u001B[38;5;241m=\u001B[39m math\u001B[38;5;241m.\u001B[39msqrt(\u001B[38;5;241m3.0\u001B[39m) \u001B[38;5;241m*\u001B[39m std  \u001B[38;5;66;03m# Calculate uniform bounds from standard deviation\u001B[39;00m\n\u001B[0;32m    517\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m--> 518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtensor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43muniform_\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43mbound\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbound\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgenerator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgenerator\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Load and Train the model\n",
    "model = YOLO('pre_trained_models/yolov8x-cls.pt')  # Yolo8\n",
    "# model = YOLO(os.path.join(output_directory, 'pre_trained_models/yolov8x-cls.pt'))  # Yolo8\n",
    "model.to(device)\n",
    "\n",
    "train_results = model.train(data=output_directory, epochs=10, seed=42, device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T01:30:39.637883800Z",
     "start_time": "2024-11-19T01:30:33.350828300Z"
    }
   },
   "id": "9fcdab206cf9d70c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prediction and evaluation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11e42f01488208d7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import best model\n",
    "best_model = YOLO('runs/classify/train/weights/best.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T01:30:39.652881300Z",
     "start_time": "2024-11-19T01:30:39.638880300Z"
    }
   },
   "id": "133a2bc2c7a4357e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Predict\n",
    "test_results = best_model.predict(source=images_test_path, save=True, device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-11-19T01:30:39.639880300Z"
    }
   },
   "id": "dfde1b053088b1cd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Prediction data preparation\n",
    "\n",
    "image_id = []\n",
    "image_prediction = []\n",
    "\n",
    "for result in test_results:\n",
    "    image_id.append(os.path.basename(result.path)[:-4])\n",
    "    image_prediction.append(result.probs.top1)\n",
    "    \n",
    "# Loading testing csv\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "\n",
    "# Create a DataFrame from predictions\n",
    "predictions_df = pd.DataFrame({\n",
    "    'id': image_id,\n",
    "    'predicted': image_prediction\n",
    "})\n",
    "\n",
    "# Convert IDs in test_df to string (to validate/match predictions_df)\n",
    "test_df['id'] = test_df['id'].astype(str)\n",
    "\n",
    "# Merge the predictions with the ground truths\n",
    "results_df = pd.merge(test_df, predictions_df, on='id', how='left')\n",
    "\n",
    "# Ensure no missing predictions\n",
    "# results_df['predicted'].fillna(0, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-11-19T01:30:39.641880900Z"
    }
   },
   "id": "9c5d46fa548c81c2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(results_df['ground_truth'], results_df['predicted'])\n",
    "precision = precision_score(results_df['ground_truth'], results_df['predicted'], average='macro')\n",
    "recall = recall_score(results_df['ground_truth'], results_df['predicted'], average='macro')\n",
    "f1 = f1_score(results_df['ground_truth'], results_df['predicted'], average='macro')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-11-19T01:30:39.644883300Z"
    }
   },
   "id": "fb51f6cbaeddede1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(results_df['ground_truth'], results_df['predicted'])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-11-19T01:30:39.645885300Z"
    }
   },
   "id": "f9129a95719c2331"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
